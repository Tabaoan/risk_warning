import os
import joblib
import traceback
import tempfile
from datetime import datetime
import pandas as pd
import numpy as np
import gradio as gr
import matplotlib.pyplot as plt

# ----------------- 1. C·∫•u h√¨nh -----------------
RISK_MODEL_PATH = "credit_risk_model.pkl"
SCORE_MODEL_PATH = "credit_score_model.pkl"
FEATURE_NAMES_PATH = "feature_names.pkl"

# ----------------- 2. Load models -----------------
if not os.path.exists(RISK_MODEL_PATH):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model risk t·∫°i '{RISK_MODEL_PATH}'.")
risk_model = joblib.load(RISK_MODEL_PATH)

if not os.path.exists(SCORE_MODEL_PATH):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model score t·∫°i '{SCORE_MODEL_PATH}'.")
score_data = joblib.load(SCORE_MODEL_PATH)
score_model = score_data['model']
score_scaler = score_data['scaler']

feature_names_from_file = None
if os.path.exists(FEATURE_NAMES_PATH):
    try:
        feature_names_from_file = joblib.load(FEATURE_NAMES_PATH)
    except Exception as e:
        print("‚ö†Ô∏è Kh√¥ng th·ªÉ load feature names t·ª´ file:", e)

base_cols = ['monthly_inc','age','debt_ratio','open_credit','real_estate',
             'late_30_59','late_60_89','late_90','dependents','rev_util']
eps = 1e-8

# ----------------- 3. H√†m extract expected features -----------------
def _extract_expected_features(model, sample_columns=None):
    if feature_names_from_file is not None:
        return list(feature_names_from_file)
    if hasattr(model, "feature_names_in_"):
        return list(model.feature_names_in_)
    return None

# ----------------- 4. Ph√¢n t√≠ch insight v√† khuy·∫øn ngh·ªã -----------------
def generate_insights(df_out):
    try:
        insights = []

        high_risk = df_out[df_out['prediction'] == 1]
        low_risk = df_out[df_out['prediction'] == 0]

        # ======= HIGH RISK GROUP =======
        if not high_risk.empty:
            avg_score = high_risk['credit_score'].mean()
            top_features = high_risk[['monthly_inc', 'debt_ratio', 'late_30_59', 'late_60_89', 'late_90']].mean().sort_values(ascending=False)

            insights.append("### Nh√≥m High Risk (R·ªßi ro cao):")
            insights.append(f"- S·ªë l∆∞·ª£ng kh√°ch h√†ng: **{len(high_risk)}**")
            insights.append(f"- Trung b√¨nh ƒëi·ªÉm t√≠n d·ª•ng: **{avg_score:.2f}**")

            insights.append("- üîç **C√°c y·∫øu t·ªë r·ªßi ro ch√≠nh:**")
            for feat, val in top_features.items():
                desc = {
                    'monthly_inc': "Thu nh·∫≠p h√†ng th√°ng cao b·∫•t th∆∞·ªùng ‚Üí c√≥ th·ªÉ l√† d·ªØ li·ªáu sai l·ªách ho·∫∑c thu nh·∫≠p kh√¥ng ·ªïn ƒë·ªãnh.",
                    'debt_ratio': "T·ª∑ l·ªá n·ª£ cao ‚Üí g√°nh n·∫∑ng t√†i ch√≠nh l·ªõn.",
                    'late_30_59': "Tr·ªÖ h·∫°n 30-59 ng√†y ‚Üí d·∫•u hi·ªáu m·∫•t kh·∫£ nƒÉng thanh to√°n nh·∫π.",
                    'late_60_89': "Tr·ªÖ h·∫°n 60-89 ng√†y ‚Üí t√¨nh tr·∫°ng n·ª£ trung b√¨nh.",
                    'late_90': "Tr·ªÖ h·∫°n ‚â•90 ng√†y ‚Üí r·ªßi ro t√≠n d·ª•ng c·ª±c cao."
                }
                explanation = desc.get(feat, "")
                insights.append(f"  - `{feat}` trung b√¨nh: **{val:.2f}** ‚Üí {explanation}")

            insights.append("-  **Khuy·∫øn ngh·ªã h√†nh ƒë·ªông:**")
            insights.append("  - Li√™n h·ªá nh√≥m n√†y ƒë·ªÉ x√°c minh thu nh·∫≠p v√† t√¨nh tr·∫°ng c√¥ng vi·ªác.")
            insights.append("  - H∆∞·ªõng d·∫´n l·∫≠p k·∫ø ho·∫°ch tr·∫£ n·ª£ v√† theo d√µi s√°t l·ªãch s·ª≠ thanh to√°n.")
            insights.append("  - T·∫°m ng·ª´ng c·∫•p th√™m t√≠n d·ª•ng cho ƒë·∫øn khi l·ªãch s·ª≠ t√≠n d·ª•ng c·∫£i thi·ªán.\n")

        # ======= LOW RISK GROUP =======
        if not low_risk.empty:
            avg_score = low_risk['credit_score'].mean()
            top_features = low_risk[['monthly_inc', 'debt_ratio', 'late_30_59', 'late_60_89', 'late_90']].mean().sort_values(ascending=False)

            insights.append("### üü¢ Nh√≥m Low Risk (R·ªßi ro th·∫•p):")
            insights.append(f"- S·ªë l∆∞·ª£ng kh√°ch h√†ng: **{len(low_risk)}**")
            insights.append(f"- Trung b√¨nh ƒëi·ªÉm t√≠n d·ª•ng: **{avg_score:.2f}**")

            num_good_payers = (low_risk[['late_30_59', 'late_60_89', 'late_90']].sum(axis=1) == 0).sum()
            insights.append(f"- **{num_good_payers} kh√°ch h√†ng (chi·∫øm {num_good_payers/len(low_risk)*100:.1f}%) kh√¥ng c√≥ l·ªãch s·ª≠ tr·ªÖ h·∫°n.**")

            insights.append("- üå± **Khuy·∫øn ngh·ªã ph√°t tri·ªÉn:**")
            insights.append("  - Xem x√©t tƒÉng h·∫°n m·ª©c t√≠n d·ª•ng ho·∫∑c gi·ªõi thi·ªáu s·∫£n ph·∫©m t√†i ch√≠nh m·ªõi.")
            insights.append("  - Tri √¢n nh√≥m kh√°ch h√†ng n√†y b·∫±ng c√°c ch∆∞∆°ng tr√¨nh th∆∞·ªüng/th·∫ª t√≠n d·ª•ng ∆∞u ƒë√£i.")
            insights.append("  - C√≥ th·ªÉ x√¢y d·ª±ng m√¥ h√¨nh kh√°ch h√†ng l√Ω t∆∞·ªüng d·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm nh√≥m n√†y.\n")

        # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá
        if not insights:
            insights.append("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p ƒë·ªÉ t·∫°o insight.")

        return "\n".join(insights)

    except Exception as e:
        return f"‚ùå L·ªói khi t·∫°o insight: {str(e)}"

# ----------------- 5. H√†m x·ª≠ l√Ω file upload -----------------
def process_file(uploaded_file):
    try:
        if uploaded_file is None:
            return [None]*9 + ["‚ùå Vui l√≤ng upload file CSV ho·∫∑c Excel."]

        fname = getattr(uploaded_file, "name", None) or str(uploaded_file)
        ext = fname.split(".")[-1].lower()
        if ext == "csv":
            df = pd.read_csv(uploaded_file.file if hasattr(uploaded_file, "file") else fname)
        elif ext in ("xls", "xlsx"):
            df = pd.read_excel(uploaded_file.file if hasattr(uploaded_file, "file") else fname)
        else:
            return [None]*9 + ["‚ùå ƒê·ªãnh d·∫°ng file kh√¥ng h·ªó tr·ª£."]

        if df.shape[0] == 0:
            return [None]*9 + ["‚ùå File r·ªóng."]

        original_df = df.copy()
        existing_output_cols = [c for c in ['prediction','prediction_label','prob_risk','credit_score'] if c in df.columns]
        overwritten = False
        if existing_output_cols:
            overwritten = True
            df = df.drop(columns=existing_output_cols, errors='ignore')

        for c in base_cols:
            if c not in df.columns:
                df[c] = 0
        for c in base_cols:
            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)

        df['income_to_debt'] = df['monthly_inc'] / (df['debt_ratio'] + eps)
        df['total_late'] = df['late_30_59'] + df['late_60_89'] + df['late_90']
        df['age_per_credit'] = df['age'] / (df['open_credit'] + eps)
        df['real_estate_ratio'] = df['real_estate'] / (df['open_credit'] + eps)

        expected = _extract_expected_features(risk_model, sample_columns=df.columns.tolist())
        if expected:
            for c in expected:
                if c not in df.columns:
                    df[c] = 0
            df_model = df.reindex(columns=expected, fill_value=0)
        else:
            df_model = df.copy()

        risk_preds = risk_model.predict(df_model)
        try:
            proba = risk_model.predict_proba(df_model)
            prob_vals = proba[:,1] if proba.shape[1]>=2 else None
        except Exception:
            prob_vals = None

        X_scaled = score_scaler.transform(df[base_cols])
        score_preds = score_model.predict(X_scaled)

        df_out = original_df.copy()
        df_out['prediction'] = risk_preds
        df_out['prediction_label'] = df_out['prediction'].map({0:'Low risk',1:'High risk'})
        df_out['credit_score'] = score_preds.round(2)
        df_out['prob_risk'] = (prob_vals*100).round(2) if prob_vals is not None else np.nan

        # ---------- Bar Chart & Insight ----------
        fig_counts = plt.figure(figsize=(6,4))
        counts = df_out['prediction_label'].value_counts()
        ax = fig_counts.subplots()
        counts.plot.bar(ax=ax, color=['green','red'])
        ax.set_title("S·ªë l∆∞·ª£ng theo lo·∫°i r·ªßi ro")
        ax.set_xlabel("Lo·∫°i")
        ax.set_ylabel("S·ªë b·∫£n ghi")
        ax.grid(axis='y', linestyle=':', linewidth=0.6)
        plt.tight_layout()
        high_count = counts.get('High risk', 0)
        low_count = counts.get('Low risk', 0)
        total_count = high_count + low_count
        high_ratio = (high_count / total_count * 100) if total_count > 0 else 0
        low_ratio = 100 - high_ratio

        counts_md = (
            f"üìä **Ph√¢n b·ªë theo lo·∫°i r·ªßi ro:**\n"
            f"- üî¥ High risk: **{high_count}** b·∫£n ghi (**{high_ratio:.1f}%**)\n"
            f"- üü¢ Low risk: **{low_count}** b·∫£n ghi (**{low_ratio:.1f}%**)\n\n"
            f"üß† **Ph√¢n t√≠ch:** Nh√≥m High risk chi·∫øm t·ª∑ l·ªá ƒë√°ng k·ªÉ trong t·ªïng d·ªØ li·ªáu, cho th·∫•y c√≥ nhi·ªÅu kh√°ch h√†ng ƒëang ·ªü tr·∫°ng th√°i t√†i ch√≠nh kh√¥ng ·ªïn ƒë·ªãnh.\n"
            f"üí° **Khuy·∫øn ngh·ªã:**\n"
            f"- T·∫≠p trung r√† so√°t v√† theo d√µi k·ªπ l∆∞·ª°ng nh√≥m High risk.\n"
            f"- √Åp d·ª•ng c√°c chi·∫øn l∆∞·ª£c ph√≤ng ng·ª´a nh∆∞ c·∫£nh b√°o s·ªõm, gi·ªõi h·∫°n t√≠n d·ª•ng v√† t∆∞ v·∫•n t√†i ch√≠nh.\n"
            f"- ƒê·ªëi v·ªõi nh√≥m Low risk, c√≥ th·ªÉ xem x√©t n√¢ng h·∫°n m·ª©c, ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m t√≠n d·ª•ng ∆∞u ƒë√£i."
        )

        # ---------- Pie Chart & Insight ----------
        fig_pie = plt.figure(figsize=(5,5))
        ax2 = fig_pie.subplots()
        labels = counts.index.tolist()
        sizes = counts.values.tolist()
        if len(sizes)==1:
            labels += ['']; sizes += [0]
        explode = [0.02]*len(sizes)
        ax2.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, explode=explode, colors=['green','red'])
        ax2.set_title("T·ª∑ l·ªá Low vs High risk")
        ax2.axis('equal')
        plt.tight_layout()
        high_pct = sizes[labels.index('High risk')]/sum(sizes)*100 if 'High risk' in labels else 0
        pie_md = (
            f"üìä T·ª∑ l·ªá High risk: **{high_pct:.1f}%** trong t·ªïng s·ªë kh√°ch h√†ng.\n"
            f"üí° **Ph√¢n t√≠ch:** T·ª∑ l·ªá n√†y ph·∫£n √°nh nh√≥m kh√°ch h√†ng c√≥ l·ªãch s·ª≠ t√≠n d·ª•ng y·∫øu, th∆∞·ªùng xuy√™n tr·ªÖ h·∫°n ho·∫∑c c√≥ t·ª∑ l·ªá n·ª£ cao.\n"
            f"üõ†Ô∏è **G·ª£i √Ω bi·ªán ph√°p c·∫£i thi·ªán:**\n"
            f"- Thi·∫øt l·∫≠p h·ªá th·ªëng nh·∫Øc n·ª£ t·ª± ƒë·ªông (qua email/SMS) tr∆∞·ªõc h·∫°n thanh to√°n.\n"
            f"- C√¢n nh·∫Øc c∆° c·∫•u l·∫°i kho·∫£n vay, gi·∫£m √°p l·ª±c tr·∫£ n·ª£ h√†ng th√°ng.\n"
            f"- T·∫°m d·ª´ng c·∫•p th√™m t√≠n d·ª•ng cho ƒë·∫øn khi kh√°ch h√†ng c·∫£i thi·ªán l·ªãch s·ª≠ tr·∫£ n·ª£.\n"
            f"- √Åp d·ª•ng ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i 'Tr·∫£ ƒë√∫ng ‚Äì TƒÉng h·∫°n m·ª©c' ƒë·ªÉ khuy·∫øn kh√≠ch h√†nh vi t√≠ch c·ª±c."
        )
        # ---------- Histogram & Insight ----------
        fig_prob = None
        prob_md = "‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu x√°c su·∫•t r·ªßi ro."
        if prob_vals is not None:
            fig_prob = plt.figure(figsize=(8,4.5))
            ax3 = fig_prob.subplots()
            values = df_out['prob_risk'].dropna().values
            counts_hist, bins, _ = ax3.hist(values, bins=30, alpha=0.6, density=True, color='skyblue')
            bin_centers = 0.5*(bins[:-1]+bins[1:])
            smooth = np.convolve(counts_hist,np.ones(5)/5,mode='same')
            ax3.plot(bin_centers,smooth,linewidth=2,label='Smoothed density')
            mean_val = values.mean(); median_val = np.median(values)
            ax3.axvline(mean_val, linestyle='--', linewidth=1.5, color='red', label=f"Mean: {mean_val:.2f}%")
            ax3.axvline(median_val, linestyle=':', linewidth=1.5, color='blue', label=f"Median: {median_val:.2f}%")
            ax3.set_title("Ph√¢n b·ªë x√°c su·∫•t r·ªßi ro (%)")
            ax3.set_xlabel("X√°c su·∫•t r·ªßi ro (%)"); ax3.set_ylabel("Density")
            ax3.grid(True, linestyle=':', linewidth=0.6)
            ax3.legend()
            plt.tight_layout()
            prob_md = f"üîπ Trung b√¨nh x√°c su·∫•t r·ªßi ro: **{mean_val:.2f}%**\nüîπ Trung v·ªã: **{median_val:.2f}%**\nüí° Nh√≥m kh√°ch h√†ng c√≥ x√°c su·∫•t >75% c·∫ßn ki·ªÉm tra k·ªπ v√† t∆∞ v·∫•n gi·∫£m r·ªßi ro."

        # ---------- Export CSV ----------
        tmpdir = tempfile.gettempdir()
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_path = os.path.join(tmpdir,f"predictions_output_{ts}.csv")
        df_out.to_csv(out_path,index=False,encoding="utf-8-sig")

        total = len(df_out)
        high_count = int((df_out['prediction']==1).sum())
        low_count = int((df_out['prediction']==0).sum())
        summary = f"**T·ªïng b·∫£n ghi:** {total}  \n**High risk:** {high_count}  \n**Low risk:** {low_count}"
        if existing_output_cols:
            summary += "  \n‚ö†Ô∏è File input c√≥ c·ªôt output tr∆∞·ªõc ƒë√≥ ƒë√£ b·ªã ghi ƒë√®."

        insight_markdown = generate_insights(df_out)
        summary += "\n\n" + insight_markdown

        return df_out, fig_counts, counts_md, fig_pie, pie_md, fig_prob, prob_md, out_path, summary

    except Exception as e:
        traceback.print_exc()
        return [None]*9 + [f"‚ùå L·ªói x·ª≠ l√Ω file: {str(e)}"]

# ----------------- 6. H√†m d·ª± ƒëo√°n single input -----------------
def predict_single(monthly_inc, age, debt_ratio, open_credit, real_estate,
                   late_30_59, late_60_89, late_90, dependents, rev_util):
    try:
        data = {c:[monthly_inc, age, debt_ratio, open_credit, real_estate,
                   late_30_59, late_60_89, late_90, dependents, rev_util][i] for i,c in enumerate(base_cols)}
        df = pd.DataFrame(data,index=[0])

        df['income_to_debt'] = df['monthly_inc'] / (df['debt_ratio'] + eps)
        df['total_late'] = df['late_30_59'] + df['late_60_89'] + df['late_90']
        df['age_per_credit'] = df['age'] / (df['open_credit'] + eps)
        df['real_estate_ratio'] = df['real_estate'] / (df['open_credit'] + eps)

        expected = _extract_expected_features(risk_model, sample_columns=df.columns.tolist())
        if expected:
            for c in expected:
                if c not in df.columns: df[c]=0
            df_model = df.reindex(columns=expected,fill_value=0)
        else:
            df_model = df.copy()

        risk_pred = risk_model.predict(df_model)[0]
        try:
            prob_val = risk_model.predict_proba(df_model)[:,1][0]
        except Exception:
            prob_val = None

        X_scaled = score_scaler.transform(df[base_cols])
        score_pred = score_model.predict(X_scaled)[0]

        df_result = pd.DataFrame({
            "Lo·∫°i k·∫øt qu·∫£": ["Prediction", "Risk label", "Probability (%)", "Credit score"],
            "Gi√° tr·ªã": [risk_pred, 'High risk' if risk_pred==1 else 'Low risk',
                        round(prob_val*100,2) if prob_val is not None else np.nan,
                        round(score_pred,2)]
        })
        return df_result
    except Exception as e:
        traceback.print_exc()
        return pd.DataFrame({"Lo·∫°i k·∫øt qu·∫£":["Error"],"Gi√° tr·ªã":[str(e)]})

# ----------------- 7. Giao di·ªán Gradio -----------------
with gr.Blocks(title="Credit Risk & Score Assessment", theme=gr.themes.Soft()) as demo:
    gr.Markdown("## üóÇÔ∏è ƒê√°nh gi√° r·ªßi ro & ƒëi·ªÉm t√≠n d·ª•ng\nB·∫°n c√≥ th·ªÉ upload file ho·∫∑c nh·∫≠p d·ªØ li·ªáu tr·ª±c ti·∫øp.")

    with gr.Tab("Upload file batch"):
        file_input = gr.File(label="Upload CSV ho·∫∑c Excel", file_types=[".csv",".xlsx",".xls"])
        run_btn = gr.Button("üîç Ch·∫°y ph√¢n lo·∫°i")
        output_table = gr.Dataframe(headers=None, label="B·∫£ng k·∫øt qu·∫£")
        
        fig_counts = gr.Plot(label="Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng")
        counts_md = gr.Markdown(label="Insight s·ªë l∆∞·ª£ng")
        
        fig_pie = gr.Plot(label="Bi·ªÉu ƒë·ªì t·ª∑ l·ªá Low vs High")
        pie_md = gr.Markdown(label="Insight t·ª∑ l·ªá")
        
        fig_prob = gr.Plot(label="Histogram x√°c su·∫•t")
        prob_md = gr.Markdown(label="Insight x√°c su·∫•t")

        download_btn = gr.File(label="T·∫£i CSV k·∫øt qu·∫£")
        summary_md = gr.Markdown()

        run_btn.click(
            process_file,
            inputs=[file_input],
            outputs=[
                output_table, 
                fig_counts, counts_md, 
                fig_pie, pie_md, 
                fig_prob, prob_md, 
                download_btn, 
                summary_md
            ]
        )

    with gr.Tab("Nh·∫≠p d·ªØ li·ªáu th·ªß c√¥ng"):
        inputs = [gr.Number(label=c, value=0) for c in base_cols]
        predict_btn = gr.Button("üîç D·ª± ƒëo√°n")
        output_single = gr.Dataframe(headers=["Lo·∫°i k·∫øt qu·∫£","Gi√° tr·ªã"])
        predict_btn.click(
            predict_single,
            inputs=inputs,
            outputs=output_single
        )

if __name__=="__main__":
    port = int(os.environ.get('PORT', 7860))
    demo.launch(
        server_name='127.0.0.1',
        server_port=port,
        share=False
    )
